\documentclass[../main.tex]{subfiles}

\begin{document}

\section{Architecture}
\label{sec:architecture}

Dés le début du projet, nous avions en tête de réaliser une implémentation multithreadé afin de maximiser les performances. Bien que l'architecture que nous
avions originellement conçue était très naïve, elle s'est avérée être un bon point de départ pour ce qu'est notre architecture finale. Celle-ci est flexible
fonctionnant autant en mode \textit{séquentiel}, c'est à dire sur un unique thread, que sur beaucoup de thread séparés. De plus, le fonctionnement parallèle
est amélioré par la présence de deux fichiers de configurations permettant d'optimiser d'avantage l'exécution sans devoir changer le code source.

L'architecture se base sur la possibilité en UDP d'écrire et de lire depuis un même socket depuis plusieurs thread en même temps. Ceci est possible car l'UDP
n'est pas un protocole qui garantit l'ordre d'arrivée des paquets. Notre programme utilise donc une série de threads pour lire depuis le socket et une série
de thread pour traiter les données et envoyer les paquets de (N)ACK. Ce premier type sera appellé \textit{receiver} tandis que le deuxième sera appellé \textit{handler}.

Chacun de ces threads a ensuite été amélioré par l'usage de \textit{sycalls} avancés permettant de drastiquement diminuer non seulement le nombre de \textit{syscalls}
exécutés mais également le nombre de paquets de types ACK que le receveur doit émettre. Ceci sera expliquer dans plus de détails dans les sections
qui suivent.

Ces threads communiquent entre eux à l'aide de deux queues de communication. La première sert à envoyer les paquets depuis le \textit{receiver} au \textit{handler}
et la deuxième fait le chemin inverse. Bien que cela soit plus complexe, cela permet une meilleure utilisation de la mémoire allouée en réutilisant les
\textit{buffers} précédemment alloués. De plus ce \textit{stream} utilise des opérations atomiques\footnote{ Opérations \textit{thread safe} ne requérant pas de verrou}
lors de l'ajout d'éléments afin d'augmenter les performances et de diminuer la latence dans le \textit{receiver}.

\subsection{Table de hachage type \textit{linear probing}}
\label{sec:hash_table}

Le but de cette table de hachage ou \textit{hash table} est de stocké la liste des clients concourants et de pouvoir rapidement identifié les nouvelles
connexions. Elle stocke une structure \textit{client\_t} qui contient les données relatives à une connexion telle que l'adresse IP, le port et l'état
de la fenêtre de réception. Cette table est partagée entre tous les \textit{receivers} et est correctement protégée par un \textit{mutex}.

La table de hachage donne un énorme avantage par rapport aux autres implémentations car elle est, en moyenne, en complexité temporelle $\mathcal{O}(1)$
sans requérir l'usage d'un \textit{socket} par connexion qui pourrait causer problème pour un très grand nombre de connexion concourantes\footnote{
    Le nombre de \textit{file descriptor} maximum autorisé par le système d'exploitation pourrait être atteint.}.

Afin de simplifier l'implémentation de celle-ci, notre table de hachage n'utilise par l'adresse IP du client mais uniquement le port de celui-ci comme
clé. Cela rend le calcul de l'index très simple : $Port \% M$ où $M$ est la capacité de la table de hachage. Ensuite, lors du \textit{linear probing},
l'adresse IP est comparée en plus du port afin de garantir l'unicité de chaque client. De plus cette comparaison est expressément faite avec
la fonction \textit{memcmp} afin d'en augmenter les performances\footnote{ \textit{memcmp} utilise SSE 4.2 comme observé dans le \textit{\hyperref[sec:annexs_call_graph]{call graph}}.}.
Ce qui veut donc dire qu'un maximum théorique de $65536$ connexions concourantes sans collisions peuvent être traité. En pratique ce nombre
est plus petit. De plus, avec une implémentation utilisant un \textit{socket} par client, la limite typique sur une machine linux serait
d'environ $511$\footnote{ $\frac{1}{2} \cdot ulimit_{typique} - 1$ où $ulimit_{typique}$ est la valeur typique du nombre maximal de \textit{file descriptor} par processur,
 le $\frac{1}{2}$ est dû au socket a à l'ouverture de fichier et le $1$ fait référence au socket global. } connexions. Alors
que notre implémentation pourrait en traiter $1024 - N$\footnote{ $ulimit_{typique} - N$ où $N$ est le nombre de \textit{stream}.} sans modification de la limite sur le nombre de \textit{file descriptor}.

\newpage

\subsection{\textit{Streams} - queue de communication}
\label{sec:syscalls}

Comme mentionné ci-dessus, la communication entre les différents \textit{threads} est assurée par des queues de communications que nous appelons \textit{streams}.
Il s'agit de liste chaînées d'éléments de types \textit{s\_node\_t}. Elle utilise des opérations atomiques pour l'insertion ce qui permet
à l'opération \textit{enqueue} de ne bloquer que très rarement en faisant du \textit{busy waiting} au lieu d'employer des \textit{mutexes}. Cela permet
au \textit{receiver} de ne jamais attendre pour insérer dans le stream. En revanche l'opération \textit{dequeue} est protégée par un \textit{mutex} et
emploie une variable de condition\footnote{ Permet de déverouiller un \textit{mutex} en attendant d'être notifié. Un autre \textit{thread} peut ensuite notifier
la condition et le \textit{mutex} sera automatiquement verouillé. Il est intéressant de noter que la documentation mentionne qu'il est autorisé
de notifier une variable conditionelle sans posséder le \textit{mutex} ce qui permet de maintenir le \textit{dequeue} sans verrou. } pour attendre la dispobilité de nouveaux éléments.

\subsection{\textit{Syscalls} avancés}
\label{sec:syscalls}

Les operations typiques effectuées sur des \textit{sockets} sont \textit{recv}, \textit{recvfrom}, \textit{send} et \textit{sendto}. Bien qu'il n'y ait rien
de mal avec ces implémentations, les auteurs de \cite{that_awesome_paper}

\subsection{\textit{Buffers} - implémentation de la window}
\label{sec:syscalls}

\subsection{\textit{Receiver} thread}
\label{sec:receiver}

Le \textit{receiver} thread est responsable pour la réception des paquets, identifier l'émetteur du paquet au travers de la table de hachage
et de les transmettre au travers du \textit{stream} aux \textit{handlers}. Elle s'occupe également d'identifier les nouveaux clients et 
des les ajouter à la table. 

\subsection{\textit{Handler} thread}
\label{sec:handler}

\subsection{Multiple \textit{Pipelines}}
\label{sec:pipelines}



\end{document}